{
  "last_node_id": 6,
  "last_link_id": 5,
  "nodes": [
    {
      "id": 1,
      "type": "LoadText",
      "pos": [50, 100],
      "size": [400, 200],
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": [1],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "LoadText"
      },
      "widgets_values": [
        "What is the capital of France? Please provide a brief answer."
      ],
      "title": "Input Prompt"
    },
    {
      "id": 2,
      "type": "OllamaTextGeneration",
      "pos": [500, 100],
      "size": [400, 300],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {
          "name": "prompt",
          "type": "STRING",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "TEXT",
          "type": "STRING",
          "links": [2],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "OllamaTextGeneration"
      },
      "widgets_values": [
        "http://localhost:11434",
        "llama3.2",
        1.0,
        0.7,
        2048,
        false
      ],
      "title": "Ollama Generate"
    },
    {
      "id": 3,
      "type": "ShowText",
      "pos": [950, 100],
      "size": [400, 200],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 2
        }
      ],
      "properties": {
        "Node name for S&R": "ShowText"
      },
      "widgets_values": [
        ""
      ],
      "title": "Output"
    },
    {
      "id": 4,
      "type": "Note",
      "pos": [50, 350],
      "size": [800, 150],
      "flags": {},
      "order": 3,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "# Ollama Text Generation Workflow\n\nThis workflow demonstrates basic text generation using Ollama.\n\n1. Enter your prompt in the 'Input Prompt' node\n2. Configure the Ollama server URL and model in the 'Ollama Generate' node\n3. Run the workflow to see the generated text in the 'Output' node\n\nDefault model: llama3.2\nDefault server: http://localhost:11434"
      ],
      "bgcolor": "#353",
      "title": "Instructions"
    }
  ],
  "links": [
    [1, 1, 0, 2, 0, "STRING"],
    [2, 2, 0, 3, 0, "STRING"]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1,
      "offset": [0, 0]
    }
  },
  "version": 0.4,
  "widget_idx_map": {},
  "seed_widgets": {}
}
